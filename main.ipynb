{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fede5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ef75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = 'data/data.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d0d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. 优化后的 Feed Concentration 解析函数\n",
    "# ==============================================================================\n",
    "def get_feed_concentrations(file_path):\n",
    "    df_raw = pd.read_excel(file_path, sheet_name='feed conc')\n",
    "    \n",
    "    target_mets = {'Ala', 'Arg', 'Asn', 'Asp', 'Cys', 'Glc', 'Gln', 'Glu', 'Pyr', \n",
    "                   'Gly', 'His', 'Ile', 'Lac', 'Leu', 'Lys', 'Met', 'Nh4', 'Phe', \n",
    "                   'Pro', 'Ser', 'Thr', 'Tyr', 'Val'}\n",
    "    names = df_raw.columns.values\n",
    "    values = df_raw.iloc[1].values # (跳过单位行)\n",
    "    \n",
    "    feed_concs = {}\n",
    "    for n, v in zip(names, values):\n",
    "        if isinstance(n, str) and n.strip() in target_mets:\n",
    "            try:\n",
    "                feed_concs[n.strip()] = float(v)\n",
    "            except ValueError:\n",
    "                pass \n",
    "                \n",
    "    return feed_concs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65344e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. 数据处理主逻辑 (计算 Mr/IR)\n",
    "# ==============================================================================\n",
    "def process_bioprocess_data(data_file, feed_concs):\n",
    "    # 读取数据\n",
    "    df = pd.read_excel(data_file, sheet_name='data')\n",
    "    \n",
    "    # --- 2.1 数据清洗 ---\n",
    "    # 删除第一行单位行 (例如包含 'h', 'mM')\n",
    "    if str(df.iloc[0]['Time']).strip() == 'h':\n",
    "        df = df.drop(0).reset_index(drop=True)\n",
    "        \n",
    "    # 强制转换为数值类型\n",
    "    cols_to_numeric = df.columns.drop(['Experiment'])\n",
    "    df[cols_to_numeric] = df[cols_to_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "    processed_dfs = []\n",
    "    unique_exps = df['Experiment'].unique()\n",
    "    \n",
    "    print(f\"开始处理 {len(unique_exps)} 个实验批次...\")\n",
    "    \n",
    "    for exp_id in unique_exps:\n",
    "        # 提取单批次数据并按时间排序\n",
    "        group = df[df['Experiment'] == exp_id].copy().sort_values('Time').reset_index(drop=True)\n",
    "        \n",
    "        # --- 2.2 物理量提取与单位统一 ---\n",
    "        # 原始数据确认：\n",
    "        # V: 270 (mL) -> 需要转 L\n",
    "        # feed volume: 7.04 (mL, 增量) -> 需要转 L\n",
    "        # sample: 0 (mL) -> 需要转 L\n",
    "        \n",
    "        V_L = group['V'] / 1000.0  # mL -> L\n",
    "        \n",
    "        # 注意：feed volume 是 Incremental (每一步加入的量)，不需要 diff\n",
    "        Feed_Vol_Incr_L = group['feed volume'] / 1000.0 \n",
    "        Sample_Vol_L = group['sample'] / 1000.0 \n",
    "        Time = group['Time']\n",
    "        \n",
    "        # 初始化结果 DataFrame\n",
    "        res = group[['Time', 'Experiment']].copy()\n",
    "        res['V_L'] = V_L\n",
    "        \n",
    "        # ==========================================\n",
    "        # 2.3 处理 Biomass (Xv)\n",
    "        # ==========================================\n",
    "        # 单位转换: Mcell/mL -> gDW/L\n",
    "        X_raw = group['X'] \n",
    "        dw_factors = np.where(Time < 100, 0.2161, 0.2875)\n",
    "        Xv_conc = X_raw * dw_factors # gDW/L\n",
    "        res['Xv'] = Xv_conc\n",
    "        \n",
    "        # 计算 Mr_Xv (单位: g)\n",
    "        # Accum 初始 = 初始质量; Update = -Sample\n",
    "        accum_X = np.zeros(len(group))\n",
    "        mass_X0 = V_L.iloc[0] * Xv_conc.iloc[0]\n",
    "        accum_X[0] = mass_X0 \n",
    "        \n",
    "        for t in range(1, len(group)):\n",
    "            # Biomass Feed=0\n",
    "            mass_out = Sample_Vol_L.iloc[t] * Xv_conc.iloc[t]\n",
    "            accum_X[t] = accum_X[t-1] - mass_out\n",
    "            \n",
    "        res['Mr_Xv'] = (V_L * Xv_conc) - accum_X\n",
    "        \n",
    "        # ==========================================\n",
    "        # 2.4 处理 mAb (Product)\n",
    "        # ==========================================\n",
    "        # 单位: mg/L -> Mass: mg\n",
    "        # 逻辑: Feed=0, Sample Removes\n",
    "        mAb_conc = group['mAb'] # mg/L\n",
    "        res['Conc_mAb'] = mAb_conc\n",
    "        \n",
    "        accum_mAb = np.zeros(len(group))\n",
    "        mass_mAb0 = V_L.iloc[0] * mAb_conc.iloc[0]\n",
    "        accum_mAb[0] = mass_mAb0\n",
    "        \n",
    "        for t in range(1, len(group)):\n",
    "            # mAb Feed=0\n",
    "            mass_out = Sample_Vol_L.iloc[t] * mAb_conc.iloc[t]\n",
    "            accum_mAb[t] = accum_mAb[t-1] - mass_out\n",
    "            \n",
    "        res['Mr_mAb'] = (V_L * mAb_conc) - accum_mAb\n",
    "        \n",
    "        # ==========================================\n",
    "        # 2.5 处理 Metabolites (Ala, Glc, etc.)\n",
    "        # ==========================================\n",
    "        for met, feed_c in feed_concs.items():\n",
    "            if met not in group.columns:\n",
    "                continue\n",
    "            \n",
    "            conc = group[met] # mM\n",
    "            \n",
    "            # 初始 Accum\n",
    "            mass_0 = V_L.iloc[0] * conc.iloc[0]\n",
    "            accum_vec = np.zeros(len(group))\n",
    "            accum_vec[0] = mass_0\n",
    "            \n",
    "            for t in range(1, len(group)):\n",
    "                # 1. Feed 带来的增加 (mmol)\n",
    "                # 使用原始增量值\n",
    "                d_feed_vol = Feed_Vol_Incr_L.iloc[t]\n",
    "                mass_in = d_feed_vol * feed_c \n",
    "                \n",
    "                # 2. Sample 带走的减少 (mmol)\n",
    "                mass_out = Sample_Vol_L.iloc[t] * conc.iloc[t]\n",
    "                \n",
    "                # 3. 更新 Accum\n",
    "                accum_vec[t] = accum_vec[t-1] + mass_in - mass_out\n",
    "                \n",
    "            # Mr 计算\n",
    "            total_mass = V_L * conc\n",
    "            mr = total_mass - accum_vec\n",
    "            \n",
    "            # 保存结果\n",
    "            res[f'Conc_{met}'] = conc\n",
    "            res[f'Mr_{met}'] = mr\n",
    "            \n",
    "        processed_dfs.append(res)\n",
    "\n",
    "    df_final = pd.concat(processed_dfs, ignore_index=True)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68caf47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在解析 Feed 配方...\n",
      "正在计算 Accum 和 Mr...\n",
      "开始处理 9 个实验批次...\n",
      "------------------------------\n",
      "处理完成。\n",
      "输出文件: processed_data_IR_final.csv\n",
      "数据维度: (189, 53)\n",
      "包含的列 (前10个): ['Time', 'Experiment', 'V_L', 'Xv', 'Mr_Xv', 'Conc_mAb', 'Mr_mAb', 'Conc_Ala', 'Mr_Ala', 'Conc_Arg']\n",
      "------------------------------\n",
      "数据预览 (Br1, Glucose):\n",
      "   Time   Conc_Glc    Mr_Glc\n",
      "0     0  72.550000  0.000000\n",
      "1    12  65.198513 -1.827211\n",
      "2    24  56.939987 -4.015453\n",
      "3    36  48.140276 -6.477662\n",
      "4    48  39.084531 -9.140549\n"
     ]
    }
   ],
   "source": [
    "# 1. 解析 Feed\n",
    "print(\"正在解析 Feed 配方...\")\n",
    "feed_concs = get_feed_concentrations(file_data)\n",
    "\n",
    "# 2. 处理数据\n",
    "print(\"正在计算 Accum 和 Mr...\")\n",
    "df_mr = process_bioprocess_data(file_data, feed_concs)\n",
    "\n",
    "# 3. 保存\n",
    "output_csv = 'processed_data_IR_final.csv'\n",
    "df_mr.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"处理完成。\")\n",
    "print(f\"输出文件: {output_csv}\")\n",
    "print(f\"数据维度: {df_mr.shape}\")\n",
    "print(f\"包含的列 (前10个): {list(df_mr.columns[:10])}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 打印前几行检验 (检查单位数量级是否合理，Mr 应该是 mmol 级别)\n",
    "print(\"数据预览 (Br1, Glucose):\")\n",
    "print(df_mr[df_mr['Experiment'] == 1][['Time', 'Conc_Glc', 'Mr_Glc']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a589b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature    | Max Abs Err  | Max Rel Err  | R2 Score   | Status\n",
      "-----------------------------------------------------------------\n",
      "Xv         | 7.66e-02     | 6.22e-02     | 0.9892     | ⚠️\n",
      "mAb        | 1.14e-13     | 1.16e-10     | 1.0000     | ✅\n",
      "Ala        | 8.88e-16     | 3.58e-16     | 1.0000     | ✅\n",
      "Arg        | 3.55e-15     | 2.80e-15     | 1.0000     | ✅\n",
      "Asn        | 4.44e-16     | 3.71e-15     | 1.0000     | ✅\n",
      "Asp        | 2.22e-16     | 1.69e-15     | 1.0000     | ✅\n",
      "Cys        | 4.44e-16     | 1.77e-15     | 1.0000     | ✅\n",
      "Glc        | 3.55e-15     | 1.49e-16     | 1.0000     | ✅\n",
      "Gln        | 3.55e-15     | 4.74e-14     | 1.0000     | ✅\n",
      "Glu        | 2.22e-16     | 6.78e-15     | 1.0000     | ✅\n",
      "Pyr        | 3.55e-15     | 2.34e-15     | 1.0000     | ✅\n",
      "Gly        | 3.55e-15     | 2.00e-16     | 1.0000     | ✅\n",
      "His        | 8.88e-16     | 1.20e-15     | 1.0000     | ✅\n",
      "Ile        | 7.11e-15     | 1.24e-14     | 1.0000     | ✅\n",
      "Lac        | 0.00e+00     | 0.00e+00     | 1.0000     | ✅\n",
      "Leu        | 3.55e-15     | 7.34e-15     | 1.0000     | ✅\n",
      "Lys        | 6.66e-16     | 3.56e-15     | 1.0000     | ✅\n",
      "Met        | 4.44e-16     | 7.91e-15     | 1.0000     | ✅\n",
      "Nh4        | 7.11e-15     | 4.36e-16     | 1.0000     | ✅\n",
      "Phe        | 3.55e-15     | 8.93e-15     | 1.0000     | ✅\n",
      "Pro        | 3.55e-15     | 1.23e-14     | 1.0000     | ✅\n",
      "Ser        | 3.55e-15     | 2.46e-15     | 1.0000     | ✅\n",
      "Thr        | 1.78e-15     | 1.55e-15     | 1.0000     | ✅\n",
      "Tyr        | 1.11e-16     | 5.25e-15     | 1.0000     | ✅\n",
      "Val        | 7.11e-15     | 6.17e-15     | 1.0000     | ✅\n"
     ]
    }
   ],
   "source": [
    "def validate_matrix(exp_id, df_mr, feature_names, org_mat_file):\n",
    "\n",
    "    \"\"\"\n",
    "    对比计算矩阵与原始矩阵，打印详细的误差统计。\n",
    "    \"\"\"\n",
    "    # Extract Exp 1\n",
    "    df_exp = df_mr[df_mr['Experiment'] == exp_id].copy()\n",
    "\n",
    "    # Total 25: Xv, mAb, + 23 mets\n",
    "    mr_cols = [col for col in df_mr.columns if col.startswith('Mr_')]\n",
    "\n",
    "    assert len(mr_cols) == 25\n",
    "\n",
    "    # Create matrix (25 x 21)\n",
    "    calculated = df_exp[mr_cols].values.T\n",
    "    original = sio.loadmat(org_mat_file)['data']['m_r'][0][exp_id-1]\n",
    "\n",
    "    n_vars = calculated.shape[0]\n",
    "    \n",
    "    print(f\"{'Feature':<10} | {'Max Abs Err':<12} | {'Max Rel Err':<12} | {'R2 Score':<10} | {'Status'}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for i in range(n_vars):\n",
    "        y_calc = calculated[i, :]\n",
    "        y_true = original[i, :]\n",
    "        \n",
    "        # 1. 绝对误差\n",
    "        abs_diff = np.abs(y_calc - y_true)\n",
    "        max_abs_err = np.max(abs_diff)\n",
    "        \n",
    "        # 2. 相对误差 (防止除以0)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            rel_diff = abs_diff / (np.abs(y_true) + 1e-6) # 加个小项防止除0\n",
    "            max_rel_err = np.max(rel_diff)\n",
    "            \n",
    "        # 3. R2 Score (衡量趋势一致性)\n",
    "        r2 = r2_score(y_true, y_calc)\n",
    "        \n",
    "        # 判定\n",
    "        status = \"✅\" if r2 > 0.99 else \"⚠️\"\n",
    "        if max_rel_err > 0.1 and max_abs_err > 0.1: status = \"❌\" # 误差超过10%且绝对值不忽略不计\n",
    "        \n",
    "        name = feature_names[i] if i < len(feature_names) else f\"Var_{i}\"\n",
    "        print(f\"{name:<10} | {max_abs_err:.2e}     | {max_rel_err:.2e}     | {r2:.4f}     | {status}\")\n",
    "\n",
    "# 定义变量名列表 (25个)\n",
    "metabolites_order = ['Ala', 'Arg', 'Asn', 'Asp', 'Cys', 'Glc', 'Gln', 'Glu', 'Pyr', 'Gly', 'His', 'Ile', 'Lac', 'Leu', 'Lys', 'Met', 'Nh4', 'Phe', 'Pro', 'Ser', 'Thr', 'Tyr', 'Val']\n",
    "feature_names = ['Xv', 'mAb'] + metabolites_order\n",
    "\n",
    "# 运行验证\n",
    "validate_matrix(exp_id=1, df_mr=df_mr, feature_names=feature_names, org_mat_file='data/data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01104b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA (7 components) 累积解释方差: 99.9337%\n",
      "S 矩阵形状: (25, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PCA 分析与 S 矩阵构建\n",
    "# ==============================================================================\n",
    "def build_reaction_correlation_matrix(csv_file, n_components=7):\n",
    "    # 读取预处理后的数据\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # 提取所有 M_r 列 (Reacted Amount)\n",
    "    # 注意顺序：Xv, mAb, Ala, Arg ... (需与之前定义的 met_list 一致)\n",
    "    met_list = ['Ala', 'Arg', 'Asn', 'Asp', 'Cys', 'Glc', 'Gln', 'Glu', 'Pyr', \n",
    "                'Gly', 'His', 'Ile', 'Lac', 'Leu', 'Lys', 'Met', 'Nh4', 'Phe', \n",
    "                'Pro', 'Ser', 'Thr', 'Tyr', 'Val']\n",
    "    mr_cols = ['Mr_Xv', 'Mr_mAb'] + [f'Mr_{m}' for m in met_list]\n",
    "    \n",
    "    # 提取数据矩阵 (Samples x Features)\n",
    "    # 这里的 Samples 是所有实验的所有时间点拼接\n",
    "    X_mr = df[mr_cols].values\n",
    "    \n",
    "    # 归一化 (Normalization) - 论文方法：除以最大绝对值\n",
    "    # Matlab: reacted_masses_pca = reacted_masses ./ max(abs(reacted_masses))\n",
    "    max_vals = np.max(np.abs(X_mr), axis=0)\n",
    "    max_vals[max_vals == 0] = 1.0 # 防止除零\n",
    "    X_norm = X_mr / max_vals\n",
    "    \n",
    "    # 执行 PCA\n",
    "    pca = PCA(n_components=n_components, svd_solver='full')\n",
    "    pca.fit(X_norm)\n",
    "    \n",
    "    # 检查解释方差\n",
    "    explained_var = np.sum(pca.explained_variance_ratio_)\n",
    "    print(f\"PCA ({n_components} components) 累积解释方差: {explained_var:.4%}\")\n",
    "    \n",
    "    # 构建 S 矩阵 (Reaction Correlation Matrix)\n",
    "    # S = PCA_Components.T * Scaling_Factors\n",
    "    # 维度: (25 features, 7 components)\n",
    "    # 每一列代表一个“宏观反应” (Macro-Reaction) 的化学计量数向量\n",
    "    S_matrix = pca.components_.T * max_vals[:, np.newaxis]\n",
    "    \n",
    "    return S_matrix, pca, max_vals\n",
    "\n",
    "# 运行\n",
    "S, pca_model, scalers = build_reaction_correlation_matrix('processed_data_IR_final.csv')\n",
    "print(\"S 矩阵形状:\", S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class HybridModelBase(nn.Module):\n",
    "    \"\"\"\n",
    "    混合模型基类，处理 S 矩阵和物理混合逻辑\n",
    "    \"\"\"\n",
    "    def __init__(self, S_matrix, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # 1. 注册 S 矩阵 (Fixed, Non-trainable)\n",
    "        # S 形状: (25, 7) -> (n_species, n_latent)\n",
    "        # 转置为 (7, 25) 以便进行线性变换: Score(1x7) @ S.T(7x25) = dMr(1x25)\n",
    "        self.S_matrix = torch.tensor(S_matrix, dtype=torch.float32).to(device)\n",
    "        self.register_buffer('S', self.S_matrix) \n",
    "        \n",
    "    def hybrid_forward_step(self, scores):\n",
    "        \"\"\"\n",
    "        混合层计算: 将 NN 输出的 Scores 转化为 Reacted Mass 的增量\n",
    "        dMr = Scores @ S.T\n",
    "        \"\"\"\n",
    "        # scores: (Batch, 7)\n",
    "        # S: (25, 7)\n",
    "        dMr = torch.matmul(scores, self.S.t()) # (Batch, 25)\n",
    "        return dMr\n",
    "\n",
    "class HybridLSTM(HybridModelBase):\n",
    "    \"\"\"\n",
    "    论文中的最佳 LSTM 架构: In(27)-ReLU(16)-LSTM(7)-Rate(7)\n",
    "    \"\"\"\n",
    "    def __init__(self, S_matrix, input_dim=27, hidden_dim=16, latent_dim=7, device='cpu'):\n",
    "        super().__init__(S_matrix, device)\n",
    "        \n",
    "        # 神经网络主体\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # LSTM 层\n",
    "        # batch_first=True -> (Batch, Seq, Feature)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=latent_dim, batch_first=True)\n",
    "        \n",
    "        # 输出映射层 (Rate Layer)\n",
    "        # 论文中 LSTM 输出 7 个状态，直接作为 Rates，或者接一个 Linear\n",
    "        # 为了灵活性，这里加一个 Linear(7->7)\n",
    "        self.fc_out = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x_seq, hidden_state=None):\n",
    "        \"\"\"\n",
    "        x_seq: (Batch, Seq_Len, 27) - 归一化后的输入序列\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x_seq.shape\n",
    "        \n",
    "        # 1. Feedforward Encoder\n",
    "        # Flatten for Linear layer: (Batch*Seq, 27)\n",
    "        x_flat = x_seq.reshape(-1, x_seq.size(2))\n",
    "        features = self.encoder(x_flat)\n",
    "        \n",
    "        # Reshape back for LSTM: (Batch, Seq, 16)\n",
    "        features = features.reshape(batch_size, seq_len, -1)\n",
    "        \n",
    "        # 2. LSTM\n",
    "        lstm_out, new_hidden = self.lstm(features, hidden_state)\n",
    "        \n",
    "        # 3. Output Layer -> Scores\n",
    "        scores = self.fc_out(lstm_out) # (Batch, Seq, 7)\n",
    "        \n",
    "        # 4. Hybrid Calculation (针对序列中的每一步)\n",
    "        # dMr: (Batch, Seq, 25)\n",
    "        dMr = torch.matmul(scores, self.S.t())\n",
    "        \n",
    "        return dMr, scores, new_hidden\n",
    "\n",
    "class HybridFFNN(HybridModelBase):\n",
    "    \"\"\"\n",
    "    论文中的典型 FFNN 架构: In(27)-Tanh(8)-Tanh(8)-Tanh(8)-Rate(7)\n",
    "    \"\"\"\n",
    "    def __init__(self, S_matrix, input_dim=27, hidden_dim=8, latent_dim=7, device='cpu'):\n",
    "        super().__init__(S_matrix, device)\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, latent_dim) # Output layer (Scores)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_seq):\n",
    "        \"\"\"\n",
    "        FFNN 处理时间序列时，实际上是将每一步独立处理 (Time-distributed)\n",
    "        \"\"\"\n",
    "        # x_seq: (Batch, Seq, 27)\n",
    "        scores = self.net(x_seq) # (Batch, Seq, 7)\n",
    "        dMr = torch.matmul(scores, self.S.t())\n",
    "        return dMr, scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hybrid-modeling-of-bioreactor-with-LSTM-main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
